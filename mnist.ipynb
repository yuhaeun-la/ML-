{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled22.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMsq5w0e6gZEs7R4AEaWwKJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuhaeun-la/ML-/blob/master/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJTO6ZhMJ7-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.examples.tutorials.nmist import input_data\n",
        "mnist=input_data.read_data_sets(\"./mnist/data/\",one_hot=True)\n",
        "\n",
        "X=tf.placeholder(tf.float32,[None,784])\n",
        "X=tf.placeholder(tf.float32,[None,10])\n",
        "keep_prob=tf.placeholder(tf.float32)\n",
        "#플레이스 홀더를 만들어, 학습시에는 0.8을 넣어 드롭아웃을 사용하도록 하고, 예측 시에는 1을 넣어 신경망 전체를 사용하도록 만들어야합니다.\n",
        "\n",
        "W1=tf.Variable(tf.random_normal([784,256],stddev=0.01))\n",
        "L1=tf.nn.relu(tf.matmul(X,W1))\n",
        "L1=tf.nn.dropout(L1,keep_prob)\n",
        "\n",
        "W2=tf.Variable(tf.random_normal([256,256],stddev=0.01))\n",
        "L2=tf.nn.relu(tf.matmul(L1,W2))\n",
        "L2=tf.nn.dropout(L2,keep_prob)\n",
        "\n",
        "W3=tf.Variable(tf.random_normal([256,10],stddev=0.01))\n",
        "model=tf.matmul(L2,W3)\n",
        "\n",
        "\n",
        "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model,labels=Y))\n",
        "optimizer=tf.train.AdamOptimizer(0.001).minimize(cost)\n",
        "\n",
        "####신경망 모델학습####\n",
        "\n",
        "init=tf.global_variables_initializer()\n",
        "sess=tf.Session()\n",
        "sess.run(init)\n",
        "## \n",
        "batch_size=100\n",
        "total_batch=int(mnist.train.num_examples/batch_size)\n",
        "\n",
        "for epoch in range(30):\n",
        "  total_cost=0\n",
        "\n",
        "  for i in range(total_batch):\n",
        "    batch_xs,batch_ys=mnist.train.next_batch(batch_size)\n",
        "    _, cost_val=sess.run([optimizer,cost],feed_dict={X:batch_xs,Y:batch_ys, keep_prob:0.8})\n",
        "    total_cost+=cost_val\n",
        "\n",
        "  print('epoch:','04%d'%(epoch+1),'avg.cost=','{:.3f}'.format(total_cost/total_batch))\n",
        "\n",
        "print('최적화 완료')\n",
        "\n",
        "####결과 확인\n",
        "\n",
        "is_correct=tf.equal(tf.argmax(model,1),tf.argmax(Y,1))\n",
        "accuracy=tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
        "print('정확도:',sess.run(accuracy,feed_dict={X:mnist.test.images,Y:mnist.test.labels,keep_prob:1}))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}